{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Lecture3_surprise.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/souradipta93/AI-applications/blob/main/Recommendation_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGlpD2t06xBm"
      },
      "source": [
        "# We will use the \"Surprise\" scikit. It's a Python scikit built for building and analyzing recommender systems that deal with explicit rating data\n",
        "# The name SurPRISE stands for Simple Python RecommendatIon System Engine\n",
        "# It uses the same Netflix dataset that we used for Clustering but the package allows us to downlaod the data directly from the website\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZa1KnH51AZ0",
        "outputId": "87aff374-c30b-41c4-b2da-9e48c5b50b8e"
      },
      "source": [
        "pip install scikit-surprise   #install surprise"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 255kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from scikit-surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp37-cp37m-linux_x86_64.whl size=1617613 sha256=cc5816498e74d88c66f777ecd67c20f4a55175a251fab40002ebff718df5b03a\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE7-J0DT8qgo",
        "outputId": "da45fb38-bc9b-445e-d0e5-8453befc6e1e"
      },
      "source": [
        "pip install numpy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la-EUn1p8urt"
      },
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset\n",
        "from surprise import Reader\n",
        "# these packages are important to read files"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdQdsyZg86vu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0f54106-79eb-4b6e-e477-ca61a0ba6c21"
      },
      "source": [
        "# Loads the builtin Movielens-100k data, it puts data in the movie notebook\n",
        "movielens = Dataset.load_builtin('ml-100k')\n",
        "\n",
        "#this command is specific to surprise package"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPEq6gpq6fC5"
      },
      "source": [
        "# look at raw ratings: \n",
        "movielens.raw_ratings[0:20]\n",
        "#the columns are\n",
        "#user id, #movie id #rating #timestamp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w_Wi77_9p-5"
      },
      "source": [
        "from surprise import KNNWithMeans\n",
        "from surprise import accuracy\n",
        "from surprise.model_selection import train_test_split\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cs8CiiWY5eag"
      },
      "source": [
        "sim_options = { #describing python model\n",
        "    \"name\": \"cosine\",# here name of algo taken\n",
        "    \"user_based\": True,# here user based or item based specified  # Compute  similarities between items\n",
        "}\n",
        "algo = KNNWithMeans(sim_options=sim_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM-8Q8Hl-Akq"
      },
      "source": [
        "trainset, testset = train_test_split(movielens, test_size=.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQCoB0Zp-GNi"
      },
      "source": [
        "algo.fit(trainset) #training the model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyo6Flhi-LOk"
      },
      "source": [
        "predictions = algo.test(testset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApjsYq3N-YLS"
      },
      "source": [
        "accuracy.rmse(predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zLRXqWqljWa"
      },
      "source": [
        "# look at raw ratings: \n",
        "movielens.raw_ratings[0:10]\n",
        "\n",
        "#user id, #movie id #rating #timestamp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiynbfXn-DYS"
      },
      "source": [
        "algo.predict('305','51') #predicting for specific uid '305'."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsaZmzmylVd8"
      },
      "source": [
        "***The rating predicted for the customer using model is 3.5, whereas actual is 3 as per data given***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jawPVW8qiguT"
      },
      "source": [
        "from collections import defaultdict # for top 10 customer predictions\n",
        "def get_top_n(predictions, n=10):\n",
        "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
        "\n",
        "    Args:\n",
        "        predictions(list of Prediction objects): The list of predictions, as\n",
        "            returned by the test method of an algorithm.\n",
        "        n(int): The number of recommendation to output for each user. Default\n",
        "            is 10.\n",
        "\n",
        "    Returns:\n",
        "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
        "        [(raw item id, rating estimation), ...] of size n.\n",
        "    \"\"\"\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_zjwmkXlsWb"
      },
      "source": [
        "**This is to give top n recommendations for each user**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soHpCz77ijHP"
      },
      "source": [
        "# Than predict ratings for all pairs (u, i) that are NOT in the training set.\n",
        "#testset = trainset.build_anti_testset()\n",
        "#predictions = algo.test(testset)\n",
        "\n",
        "top_n = get_top_n(predictions, n=5)\n",
        "\n",
        "# Print the recommended items for each user\n",
        "#for uid, user_ratings in top_n.items():\n",
        " #   print(uid, [iid for (iid, _) in user_ratings])\n",
        "top_n.items()\n",
        "\n",
        "#creating top 5 predictions in test dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAx4AUnRiiye"
      },
      "source": [
        "**These are the top predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iNT9fBHb12Z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}